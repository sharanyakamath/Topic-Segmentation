{"cells":[{"cell_type":"code","source":["!python3 /content/drive/MyDrive/SEM2/696DS/cross-segment/config_setup.py"],"metadata":{"id":"HTJB7Ee75FnJ","executionInfo":{"status":"ok","timestamp":1645917835433,"user_tz":300,"elapsed":983,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip3 install pathlib2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hsCR7nEKVtE-","executionInfo":{"status":"ok","timestamp":1645917856527,"user_tz":300,"elapsed":3843,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"outputId":"63f1982a-cb4f-49b3-c203-8c362459589e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pathlib2\n","  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2) (1.15.0)\n","Installing collected packages: pathlib2\n","Successfully installed pathlib2-2.3.7.post1\n"]}]},{"cell_type":"code","source":["!pip3 install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGAU0SV8WP-R","executionInfo":{"status":"ok","timestamp":1645917872261,"user_tz":300,"elapsed":15754,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"outputId":"ad836443-556b-4ea4-be58-45040f86737c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[?25l\r\u001b[K     |                                | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |▏                               | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |▎                               | 30 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |▍                               | 40 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |▌                               | 51 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 61 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 71 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 81 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 92 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 102 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 112 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 122 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 133 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 143 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 153 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 163 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 174 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 184 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 194 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 204 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 215 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 225 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 235 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 245 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 256 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 266 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 276 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 286 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 296 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 307 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 317 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 327 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 337 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 348 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 358 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 368 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 378 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 389 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 399 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 409 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 419 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 430 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 440 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 450 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 460 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 471 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 481 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 491 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 501 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 512 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 522 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 532 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 542 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 552 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 563 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 573 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 583 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 593 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 604 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 614 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 624 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 634 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 645 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 655 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 665 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 675 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 686 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 696 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 706 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 716 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 727 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 737 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 747 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 757 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 768 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 778 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 788 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 798 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 808 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 819 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 829 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 839 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 849 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 860 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 870 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 880 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 890 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 901 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 911 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 921 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 931 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 942 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 952 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 962 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 972 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 983 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 993 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 1.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 1.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 1.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 1.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 1.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 2.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 2.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.6 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.7 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.8 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.9 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 3.0 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 3.1 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 3.2 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.3 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.4 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.5 MB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.5 MB 24.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 46.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 41.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"]}]},{"cell_type":"code","source":["!python3 /content/drive/MyDrive/SEM2/696DS/cross-segment/wiki_loader.py"],"metadata":{"id":"8ljfohR5j0QT","executionInfo":{"status":"ok","timestamp":1645921405217,"user_tz":300,"elapsed":2897,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!python3 /content/drive/MyDrive/SEM2/696DS/cross-segment/training.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27QWJMfd5gr4","executionInfo":{"status":"ok","timestamp":1645921578468,"user_tz":300,"elapsed":14040,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"outputId":"ac8da86c-d346-41cc-f960-d93bfec10dbe"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/train\n","/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/train/paths_cache.txt\n","/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/dev\n","/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/dev/paths_cache.txt\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","model will run on: cuda:0\n","\n"," Epoch 1 / 1\n","  0% 0/12787 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","  0% 0/12787 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/SEM2/696DS/cross-segment/training.py\", line 321, in <module>\n","    train_loss = train(train_dataloader, is_early=True)\n","  File \"/content/drive/MyDrive/SEM2/696DS/cross-segment/training.py\", line 177, in train\n","    loss = CELoss(preds, labels)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\", line 1152, in forward\n","    label_smoothing=self.label_smoothing)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n","    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n","ValueError: Expected input batch_size (172) to match target batch_size (152).\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"sO4IzQaY2lLW","executionInfo":{"status":"ok","timestamp":1645921618249,"user_tz":300,"elapsed":1642,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","#from text_manipulation import word_model\n","#from text_manipulation import extract_sentence_words\n","from nltk.tokenize import RegexpTokenizer\n","from pathlib2 import Path\n","import re\n","import os\n","import math\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1PqNa6v2osz","executionInfo":{"status":"ok","timestamp":1645917847238,"user_tz":300,"elapsed":1044,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"outputId":"3c6e18b3-edb3-441f-f655-d6e1abd56e93"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXEQxtdL2lLb","executionInfo":{"status":"ok","timestamp":1645921625522,"user_tz":300,"elapsed":4511,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"outputId":"8f9040ca-142c-4148-9d9b-67c284403ffd"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["import transformers\n","from transformers import AdamW\n","from transformers import BertModel, BertTokenizer\n","\n","bert = BertModel.from_pretrained('bert-base-uncased')\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","MAX_TOKENS = 200\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"dunv5ClS2lLc","executionInfo":{"status":"ok","timestamp":1645921630131,"user_tz":300,"elapsed":364,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}}},"outputs":[],"source":["#logger = utils.setup_logger(__name__, 'train.log')\n","missing_stop_words = set(['of', 'a', 'and', 'to'])\n","section_delimiter = \"========\"\n","segment_seperator = \"========\"\n","\n","def get_list_token():\n","    return \"***LIST***\"\n","\n","def get_formula_token():\n","    return \"***formula***\"\n","\n","def get_codesnipet_token():\n","    return \"***codice***\"\n","\n","def get_special_tokens():\n","    special_tokens = []\n","    special_tokens.append(get_list_token())\n","    special_tokens.append(get_formula_token())\n","    special_tokens.append(get_codesnipet_token())\n","    return special_tokens\n","\n","def get_seperator_foramt(levels = None):\n","    level_format = '\\d' if levels == None else '['+ str(levels[0]) + '-' + str(levels[1]) + ']'\n","    seperator_fromat = segment_seperator + ',' + level_format + \",.*?\\.\"\n","    return seperator_fromat\n","\n","words_tokenizer = None\n","def get_words_tokenizer():\n","    global words_tokenizer\n","\n","    if words_tokenizer:\n","        return words_tokenizer\n","\n","    words_tokenizer = RegexpTokenizer(r'\\w+')\n","    return words_tokenizer\n","\n","def extract_sentence_words(sentence, remove_missing_emb_words = False, remove_special_tokens = False):\n","    if (remove_special_tokens):\n","        for token in get_special_tokens():\n","            # Can't do on sentence words because tokenizer delete '***' of tokens.\n","            sentence = sentence.replace(token, \"\")\n","    tokenizer = get_words_tokenizer()\n","    sentence_words = tokenizer.tokenize(sentence)\n","    if remove_missing_emb_words:\n","        sentence_words = [w for w in sentence_words if w not in missing_stop_words]\n","\n","    return sentence_words\n","\n","\n","def word_model(word, model): #http://127.0.0.1:8990/?token=bf09ebab079e0fa44f92e9781373743116328722bca9e067\n","    if model is None:\n","        return np.random.randn(1, 300)\n","    else:\n","        if word in model:\n","            return model[word].reshape(1, 300)\n","        else:\n","            #print ('Word missing w2v: ' + word)\n","            return model['UNK'].reshape(1, 300)\n","\n","def get_files(path):\n","    all_objects = Path(path).glob('**/*')\n","    files = [str(p) for p in all_objects if p.is_file()]\n","    return files\n","\n","\n","def get_cache_path(wiki_folder):\n","    cache_file_path = wiki_folder / 'paths_cache'\n","    return cache_file_path\n","\n","\n","def cache_wiki_filenames(wiki_folder):\n","    files = Path(wiki_folder).glob('*/*/*/*')\n","    cache_file_path = get_cache_path(wiki_folder)\n","\n","    with cache_file_path.open('w+') as f:\n","        for file in files:\n","            f.write(file + u'\\n')\n","\n","\n","def clean_section(section):\n","    cleaned_section = section.strip('\\n')\n","    return cleaned_section\n","\n","\n","def get_scections_from_text(txt, high_granularity=True):\n","    sections_to_keep_pattern = get_seperator_foramt() if high_granularity else get_seperator_foramt(\n","        (1, 2))\n","    if not high_granularity:\n","        # if low granularity required we should flatten segments within segemnt level 2\n","        pattern_to_ommit = get_seperator_foramt((3, 999))\n","        txt = re.sub(pattern_to_ommit, \"\", txt)\n","\n","        #delete empty lines after re.sub()\n","        sentences = [s for s in txt.strip().split(\"\\n\") if len(s) > 0 and s != \"\\n\"]\n","        txt = '\\n'.join(sentences).strip('\\n')\n","\n","\n","    all_sections = re.split(sections_to_keep_pattern, txt)\n","    non_empty_sections = [s for s in all_sections if len(s) > 0]\n","\n","    return non_empty_sections\n","\n","\n","def get_sections(path, high_granularity=True):\n","    file = open(str(path), \"r\")\n","    raw_content = file.read()\n","    file.close()\n","\n","    clean_txt = raw_content.strip()\n","\n","    sections = [clean_section(s) for s in get_scections_from_text(clean_txt, high_granularity)]\n","\n","    return sections\n","\n","def read_wiki_file(path, n_context_sent = 1, remove_preface_segment=True, high_granularity=True):\n","    data = []\n","    targets = []\n","    all_sections = get_sections(path, high_granularity)\n","    required_sections = all_sections[1:] if remove_preface_segment and len(all_sections) > 0 else all_sections\n","    required_non_empty_sections = [section for section in required_sections if len(section) > 0 and section != \"\\n\"]\n","\n","    list_sentence = get_list_token() + \".\"\n","    final_sentences = []\n","    label = []\n","    for section_ind in range(len(required_non_empty_sections)):\n","        sentences_ = required_non_empty_sections[section_ind].split('\\n')\n","        sentences = [x for x in sentences_ if x != list_sentence]\n","        if sentences:\n","            for sentence in sentences[:-1]:\n","                final_sentences.append(sentence)\n","                label.append(0)\n","            final_sentences.append(sentences[-1])\n","            label.append(1)\n","    \n","    if len(final_sentences)>n_context_sent:\n","        for sent_ind in range(n_context_sent,len(final_sentences)):\n","            prev_context = final_sentences[sent_ind-n_context_sent:sent_ind]\n","            after_context = final_sentences[sent_ind: min(len(final_sentences),sent_ind+n_context_sent)]\n","            \n","            prev_context = \" \".join(prev_context)\n","            after_context = \" \".join(after_context)\n","            data.append([prev_context, after_context])\n","            targets.append(label[sent_ind-1])\n","\n","    return data, targets, path\n","\n","\n","class WikipediaDataSet(Dataset):\n","    def __init__(self, root,n_context_sent = 1, train=True, manifesto=False, folder=False, high_granularity=False):\n","\n","        if (manifesto):\n","            self.textfiles = list(Path(root).glob('*'))\n","        else:\n","            if (folder):\n","                self.textfiles = get_files(root)\n","            else:\n","                root_path = Path(root)\n","                print(root_path)\n","                cache_path = get_cache_path(root_path)\n","                print(cache_path)\n","                if not cache_path.exists():\n","                    print(\"not_exist\")\n","                    cache_wiki_filenames(root_path)\n","                self.textfiles = cache_path.read_text().splitlines()\n","\n","        if len(self.textfiles) == 0:\n","            raise RuntimeError('Found 0 images in subfolders of: {}'.format(root))\n","        self.train = train\n","        self.root = root\n","        self.high_granularity = high_granularity\n","        self.n_context_sent = n_context_sent\n","\n","    def __getitem__(self, index):\n","        path = self.textfiles[index]\n","\n","        return read_wiki_file(Path(path),n_context_sent = 2,high_granularity=self.high_granularity)\n","\n","    def __len__(self):\n","        return len(self.textfiles)\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"r36Xr0Xs2lLj","colab":{"base_uri":"https://localhost:8080/","height":374},"outputId":"8573d880-d744-4c3a-9ce5-d223198a84ee","executionInfo":{"status":"error","timestamp":1645921899320,"user_tz":300,"elapsed":165,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/dev\n","/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/dev/paths_cache\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-2bdf31f54686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWikipediaDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_granularity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-ce469543e745>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, n_context_sent, train, manifesto, folder, high_granularity)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found 0 images in subfolders of: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found 0 images in subfolders of: /content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727/dev"]}],"source":["\n","def collate_fn(batch):\n","    batched_data = []\n","    batched_targets = []\n","    batched_paths = []\n","\n","    window_size = 1\n","    before_sentence_count = int(math.ceil(float(window_size - 1) /2))\n","    after_sentence_count = window_size - before_sentence_count - 1\n","    max_tokens = 100\n","    for data, targets, path in batch:\n","        try:\n","            for i in range(len(data)):\n","                temp = len(data[i][0].split())+len(data[i][1].split())\n","                if max_tokens < temp:\n","                    max_tokens = temp\n","                batched_data.append(data[i])\n","                batched_targets.append(targets[i])\n","                batched_paths.append(path)\n","        except Exception as e:\n","            logger.info('Exception \"%s\" in file: \"%s\"', e, path)\n","            logger.debug('Exception!', exc_info=True)\n","            continue\n","    \n","    max_tokens = min(MAX_TOKENS, max_tokens)\n","    tokens = tokenizer(\n","                    batched_data,\n","                    padding = True,\n","                    max_length = max_tokens,\n","                    truncation=True)\n","    '''seq = torch.tensor(tokens['input_ids'])\n","    mask = torch.tensor(tokens['attention_mask'])\n","    y = torch.tensor(batched_targets)'''\n","        \n","    return tokens['input_ids'], tokens['attention_mask'], batched_targets, batched_paths\n","\n","\n","dataset_path = \"/content/drive/MyDrive/SEM2/696DS/supervised-learning/wiki_727\"\n","dataset = WikipediaDataSet(dataset_path+'/dev', high_granularity=False)\n","dl = DataLoader(dataset_path, batch_size=12, collate_fn = collate_fn, shuffle=True)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"2tG5pa0I2lLk","executionInfo":{"status":"ok","timestamp":1645921809961,"user_tz":300,"elapsed":148,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"82f8dc2b-1036-4df5-bee7-190d6e6aba78"},"outputs":[{"output_type":"stream","name":"stdout","text":["6\n"]}],"source":["print(len(dl))"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Bpn2zVzZ2lLk","executionInfo":{"status":"error","timestamp":1645921820834,"user_tz":300,"elapsed":145,"user":{"displayName":"Sharanya Kamath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzL8kH1G-5lzjmR6yJcK4sC02ZLZ-Z2vFmL1dq=s64","userId":"09721328020742675021"}},"colab":{"base_uri":"https://localhost:8080/","height":200},"outputId":"0ecd8683-9b2c-40e7-adaa-407f009d7015"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-dc6e303a8178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute '__getitem__'"]}],"source":["sent,target,path = dataset.__getitem__(1)\n","print(sent[0][0])\n","print(len(sent),len(target))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QG7QLPG42lLl"},"outputs":[],"source":["print(len(sent[0]))\n","print(sent[1])\n","print(sent[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyZjAnR22lLl"},"outputs":[],"source":["tokens = tokenizer(\n","                    sent,\n","                    padding = True,\n","                    max_length = 200,\n","                    truncation=True)\n","print(tokenizer.decode(tokens['input_ids'][2]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDbYDZep2lLm"},"outputs":[],"source":["print(len(dl))\n","_,batch = next(enumerate(dl))\n","print(len(batch))\n","input_, mask, targets, paths = batch\n","print(len(input_),len(mask),len(targets))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGnZAKJT2lLn"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoSERvPc2lLn"},"outputs":[],"source":["for param in bert.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCTi3YdY2lLn"},"outputs":[],"source":["class Encoder_Classifier(nn.Module):\n","    def __init__(self, bert, n_classes):\n","        super(Encoder_Classifier, self).__init__()\n","        self.bert = bert\n","\n","        # dropout layer\n","        self.dropout = nn.Dropout(0.1)\n","\n","        # relu activation function\n","        self.relu =  nn.ReLU()\n","\n","        # dense layer 1\n","        self.fc1 = nn.Linear(768,n_classes)\n","        \n","        #softmax activation function\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","        #pass the inputs to the model  \n","        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n","\n","\n","        x = self.fc1(cls_hs) \n","\n","        # apply softmax activation\n","        x = self.softmax(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZQkhCy_2lLo"},"outputs":[],"source":["def train(train_dataloader):\n","    model.train()\n","\n","    total_loss, total_accuracy = 0, 0\n","    '''\n","    # empty list to save model predictions\n","    total_preds=[]'''\n","  \n","    # iterate over batches\n","    for step,batch in enumerate(train_dataloader):\n","\n","        # push the batch to gpu\n","        #batch = [r.to(device) for r in batch]\n","\n","        ###### for  labeled data, computing cross entropy   #########\n","        sent_id, mask, labels = torch.tensor(batch[0]).to(device),torch.tensor(batch[1]).to(device),torch.tensor(batch[2]).to(device)\n","\n","        model.zero_grad()        \n","        preds = model(sent_id, mask)\n","        loss = CELoss(preds, labels)\n","\n","        # backward pass to calculate the gradients\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters\n","        optimizer.step()\n","        \n","        #torch.cuda.empty_cache()\n","        # add on to the total loss\n","        loss_item = loss.item()\n","        total_loss += loss_item\n","\n","        # progress update after every 100 batches.\n","        if step % 100 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","            print(\"loss\",loss_item)\n","\n","         \n","\n","        '''\n","        # model predictions are stored on GPU. So, push it to CPU\n","        preds=preds.detach().cpu().numpy()\n","\n","        # append the model predictions\n","        total_preds.append(preds)'''\n","\n","    # compute the training loss of the epoch\n","    avg_loss = total_loss / len(train_dataloader)\n","    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    #total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    #returns the loss and predictions\n","    return avg_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elnuJJNJ2lLp"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","def evaluate(dev_dataloader):\n","  \n","    print(\"\\nEvaluating...\")\n","  \n","    # deactivate dropout layers\n","    model.eval()\n","    total_loss, total_accuracy = 0, 0\n","    total_preds = [[None,None]]\n","    count=0\n","    curr_examples = 0\n","\n","    # iterate over batches\n","    for step,batch in enumerate(dev_dataloader):\n","    \n","        # Progress update every 50 batches.\n","        if step % 1 == 0 and not step == 0:\n","      \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,} accuracy {}.'.format(step, len(dev_dataloader), count/curr_examples))\n","            temp = np.delete(total_preds,0,0)\n","            print(\"F1 score {}\".format(f1_score(list(temp[:,0]),list(temp[:,1]),average=\"macro\")))\n","        # push the batch to gpu\n","        #batch = [t.to(device) for t in batch]\n","    \n","\n","        sent_id, mask, labels = torch.tensor(batch[0]).to(device),torch.tensor(batch[1]).to(device),torch.tensor(batch[2]).to(device)\n","        curr_examples += len(sent_id)\n","        # deactivate autograd\n","        with torch.no_grad():\n","      \n","        # model predictions\n","            preds = model(sent_id, mask)\n","\n","            # compute the validation loss between actual and predicted values\n","            loss = CELoss(preds,labels)\n","\n","            total_loss = total_loss + loss.item()\n","            preds = preds.detach().cpu().numpy()\n","\n","            true_class = np.expand_dims(np.argmax(preds,axis=1),axis=0)\n","            labels = np.expand_dims(labels.detach().cpu().numpy(), axis=0)\n","            temp = np.concatenate((labels,true_class),axis=0).T\n","            \n","            total_preds = np.concatenate((total_preds,temp),axis=0)\n","\n","            \n","            for myvar in range(len(labels[0])):\n","                if labels[0][myvar]== true_class[0][myvar]:\n","                    count+=1\n","\n","    # compute the validation loss of the epoch\n","    avg_loss = total_loss / len(dev_dataloader) \n","\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","    print(\"Validation accuracy\",count/len(dev_data))\n","\n","    return avg_loss, count/len(dev_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvMYBBnI2lLp"},"outputs":[],"source":["best_valid_loss = float('inf')\n","train_losses = []\n","valid_losses = []\n","accuracy_list = []\n","learning_rate = .0005\n","freezed_epochs = 1\n","unfreezed_epochs = 1\n","n_classes = 2\n","n_layer_unfreeze = 2\n","weight = .3\n","device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n","CELoss = nn.CrossEntropyLoss()\n","model = Encoder_Classifier(bert, n_classes).to(device)\n","optimizer = AdamW(model.parameters(),lr = learning_rate)\n","print(device)\n","\n","dataset_path = \"/home/aakash/amagi/data/wiki/wiki_727\"\n","dataset_train = WikipediaDataSet(dataset_path+'/dev', high_granularity=False)\n","train_dataloader = DataLoader(dataset_train, batch_size=2, collate_fn = collate_fn, shuffle=True)\n","\n","dataset_dev = WikipediaDataSet(dataset_path+'/test', high_granularity=False)\n","dev_dataloader = DataLoader(dataset_dev, batch_size=2, collate_fn = collate_fn, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mry8O4CJ2lLq"},"outputs":[],"source":["for epoch in range(freezed_epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, freezed_epochs))\n","    \n","    #train model\n","    train_loss = train(train_dataloader)\n","    \n","    #evaluate model\n","    valid_loss, accuracy = evaluate(dev_dataloader)\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    accuracy_list.append(accuracy)\n","\n","    print(f'\\nTraining Loss: {train_loss[0]:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bH30DYn_2lLq"},"outputs":[],"source":["torch.save(model.state_dict(), '/home/aakash/amagi/data/wiki/wiki_727/saved_weights.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNY3XV_N2lLq"},"outputs":[],"source":["##### unfreezing layers #######\n","for iter in range(n_layer_unfreeze):\n","    print(str(iter+1)+\" unfreeze\")\n","    for param in model.bert.encoder.layer._modules[str(11-iter)].parameters():\n","        param.requires_grad=True\n","    for epoch in range(unfreezed_epochs):\n","     \n","        print('\\n Epoch {:} / {:}'.format(epoch+1 , ))\n","        \n","        #train model\n","        train_loss = train(train_dataloader)\n","    \n","        #evaluate model\n","        valid_loss, accuracy = evaluate(dev_dataloader)\n","        \n","        #save the best model\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), 'saved_weights.pt')\n","        \n","        # append training and validation loss\n","        train_losses.append(train_loss)\n","        valid_losses.append(valid_loss)\n","        accuracy_list.append(accuracy)\n","        \n","        print(f'\\nTraining Loss: {train_loss[0]:.3f}')\n","        print(f'Validation Loss: {valid_loss:.3f}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"cross_segment_bert.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}